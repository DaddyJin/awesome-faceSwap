# Awesome faceSwap

## Papers

### 2022
- <a name="todo"></a> Smooth-Swap: A Simple Enhancement for Face-Swapping With Smoothness (**CVPR 2022**) [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Smooth-Swap_A_Simple_Enhancement_for_Face-Swapping_With_Smoothness_CVPR_2022_paper.pdf)] 
- <a name="todo"></a> Region-Aware Face Swapping (**CVPR 2022**) [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Region-Aware_Face_Swapping_CVPR_2022_paper.pdf)] [[code](https://github.com/xc-csc101/RAFSwap)] 
- <a name="todo"></a> MobileFaceSwap: A Lightweight Framework for Video Face Swapping (**AAAI 2022**) [[paper](https://arxiv.org/abs/2201.03808)] [[code](https://github.com/Seanseattle/MobileFaceSwap)] 
- <a name="todo"></a> FSGANv2: Improved Subject Agnostic Face Swapping and Reenactment (**PAMI 2022**) [[paper](https://arxiv.org/abs/2202.12972)] 
- <a name="todo"></a> Few-Shot Head Swapping in the Wild (**CVPR 2022**) [[paper](https://arxiv.org/abs/2204.13100)] [[code](https://github.com/jmliu88/HeSer)] 
- <a name="todo"></a> High-resolution Face Swapping via Latent Semantics Disentanglement (**CVPR 2022**) [[paper](https://arxiv.org/abs/2203.15958)] [[code](https://github.com/cnnlstm/FSLSD_HiRes)] 
- <a name="todo"></a> A new face swap method for image and video domains: a technical report (**CVPR 2022**) [[paper](https://arxiv.org/abs/2202.03046)]


### 2021
- <a name="todo"></a> One Shot Face Swapping on Megapixels. (**CVPR 2021**) [[paper](https://arxiv.org/pdf/2106.09965)] [[code_unofficial](https://github.com/mindslab-ai/hififace)] 
- <a name="todo"></a> FaceInpainter: High Fidelity Face Adaptation to Heterogeneous Domains (**CVPR 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_FaceInpainter_High_Fidelity_Face_Adaptation_to_Heterogeneous_Domains_CVPR_2021_paper.pdf)]
- <a name="todo"></a> Information Bottleneck Disentanglement for Identity Swapping (**CVPR 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Information_Bottleneck_Disentanglement_for_Identity_Swapping_CVPR_2021_paper.pdf)]
- <a name="todo"></a> HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping (**IJCAI 2021**) [[paper](https://arxiv.org/abs/2105.04932)] [[code](https://github.com/zyainfal/One-Shot-Face-Swapping-on-Megapixels)] 


### 2020
- <a name="todo"></a> FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping (**CVPR 2020**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Li_Advancing_High_Fidelity_Identity_Swapping_for_Forgery_Detection_CVPR_2020_paper.html)] [[code_unofficial](https://github.com/mindslab-ai/faceshifter)]
- <a name="todo"></a> DeeperForensics-1.0: A Large-Scale Dataset for Real-World Face Forgery Detection (**CVPR 2020**) [[paper](https://arxiv.org/abs/2001.03024)] 
- <a name="todo"></a> DeepFaceLab: A simple, flexible and extensible face swapping framework (**arXiv 2020**) [[paper](http://arxiv.org/abs/2005.05535)] [[code](https://github.com/iperov/DeepFaceLab)] 
- <a name="todo"></a> High-Resolution Neural Face Swapping for Visual Effects (**EGSR 2020**) [[paper](https://studios.disneyresearch.com/2020/06/29/high-resolution-neural-face-swapping-for-visual-effects/)]
- <a name="todo"></a> AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection (**NIPS 2020**) [[paper](https://arxiv.org/abs/2011.02674v1)]
- <a name="todo"></a> SimSwap: An Efficient Framework For High Fidelity Face Swapping (**MM 2020**) [[paper](https://arxiv.org/pdf/2106.06340v1.pdf)] [[code](https://github.com/neuralchen/SimSwap)] 

### 2019
- <a name="todo"></a> FSGAN: Subject Agnostic Face Swapping and Reenactment (**ICCV 2019**) [[paper](http://arxiv.org/abs/1908.05932)] [[code](https://github.com/YuvalNirkin/fsgan)] 

### 2018
- <a name="todo"></a> On Face Segmentation, Face Swapping, and Face Perception (**FG 2018**) [[paper](http://arxiv.org/abs/1704.06729)] [[code](https://github.com/YuvalNirkin/face_swap)] 

### 2017
- <a name="todo"></a> Fast Face-swap Using Convolutional Neural Networks (**ICCV 2017**) [[paper](http://arxiv.org/abs/1611.09577)] 
